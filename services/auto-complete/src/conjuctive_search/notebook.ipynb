{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "# from operator import itemgetter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(query):\n",
    "    query = query.split()\n",
    "    if len(query) == 1:\n",
    "        prefix = ['']\n",
    "    else:\n",
    "        prefix = query[:-1]\n",
    "    suffix = [query[-1]]\n",
    "    return prefix, suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst_of_lst):\n",
    "    return list(set.intersection(*map(set,lst_of_lst)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Union(lst_of_list):\n",
    "    final_list = list(set().union(*lst_of_list))\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.word = None\n",
    "    \n",
    "    def insert(self, word):\n",
    "        node = self\n",
    "        for letter in word:\n",
    "            if letter not in node.children:\n",
    "                node.children[letter] = Node()\n",
    "            node = node.children[letter]\n",
    "        node.word = word\n",
    "        return node\n",
    "    def traverse(self, query):\n",
    "        node = self\n",
    "        for letter in query:\n",
    "            child = node.children.get(letter)\n",
    "            if child:\n",
    "                node = child\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return node\n",
    "    def __repr__(self):\n",
    "        return f'< children: {list(self.children.keys())}, word: {self.word} >'\n",
    "    def get_descendants_nodes(self):\n",
    "        que = collections.deque()\n",
    "        for letter, child_node in self.children.items():\n",
    "            que.append((letter, child_node))\n",
    "        while que:\n",
    "            letter, child_node = que.popleft()\n",
    "            if child_node.word:\n",
    "                yield child_node\n",
    "            for letter, grand_child_node in child_node.children.items():\n",
    "                que.append((letter, grand_child_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConjuctiveSearch(object):\n",
    "    def __init__(self, vocabulary_file, inverted_file, corpus_file):\n",
    "        data = []\n",
    "        with open(vocabulary_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f.readlines():\n",
    "                data.append(line.strip())\n",
    "\n",
    "        inverted_list = []\n",
    "        with open(inverted_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.strip().split()\n",
    "                \n",
    "                inverted_list.append(list(map(int, line[1:])))\n",
    "\n",
    "\n",
    "        self.corpus_docid = []\n",
    "        with open(corpus_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f.readlines():\n",
    "                self.corpus_docid.append(line.strip())\n",
    "\n",
    "\n",
    "        self.root = Node()\n",
    "        WORDS = data\n",
    "        for word in WORDS:\n",
    "            self.root.insert(word)\n",
    "\n",
    "        self.term2id = {}\n",
    "        self.term2inverted = {}\n",
    "        id = 1\n",
    "        for term, ivt in zip(data, inverted_list):\n",
    "            self.term2id[term] = id\n",
    "            self.term2inverted[term] = ivt\n",
    "            id += 1\n",
    "    \n",
    "    def get_candidate_suffix(self, suffix):\n",
    "        candidate_id = []\n",
    "        candidate_term = []\n",
    "\n",
    "        inverted_lst = []\n",
    "\n",
    "        found_node = self.root.traverse(query=suffix)\n",
    "        for i in list(found_node.get_descendants_nodes()):\n",
    "            term = i.word\n",
    "            candidate_term.append(term)\n",
    "            candidate_id.append(self.term2id[term])\n",
    "            inverted_lst.append(self.term2inverted[term])\n",
    "        l = min(candidate_id)\n",
    "        r = max(candidate_id)\n",
    "        return [l, r], candidate_term, Union(inverted_lst)\n",
    "    \n",
    "    def parsePrefix(self, query):\n",
    "        query = query.split()\n",
    "        if len(query) == 1:\n",
    "            prefix = ['']\n",
    "        else:\n",
    "            prefix = query[:-1]\n",
    "        suffix = [query[-1]]\n",
    "        return prefix, suffix\n",
    "    \n",
    "    def IntersectionIterator(self, prefix):\n",
    "        lst_of_lst = []\n",
    "        try:\n",
    "            for i in prefix:\n",
    "                try:\n",
    "                    lst_of_lst.append(self.term2inverted[i])\n",
    "                except:\n",
    "                    print(i)\n",
    "            # print(lst_of_lst)\n",
    "            return intersection(lst_of_lst=lst_of_lst)\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "    \n",
    "    def run(self, query):\n",
    "        prefix, suffix = self.parsePrefix(query)\n",
    "        [l, r], candidate_term, union_suffix_inverted_lst = self.get_candidate_suffix(suffix[0])\n",
    "        # print(union_suffix_inverted_lst)\n",
    "        # check complete suffix #TODO\n",
    "        if not prefix[0]:\n",
    "            return candidate_term\n",
    "        x = self.IntersectionIterator(prefix)\n",
    "        # print(x)\n",
    "        if not x:\n",
    "            return candidate_term\n",
    "        docid = intersection(lst_of_lst=[x, union_suffix_inverted_lst])\n",
    "        if not docid:\n",
    "            return candidate_term\n",
    "        return list(map(self.corpus_docid.__getitem__, docid))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = ConjuctiveSearch('../build_db/completions.dict', '../build_db/completions.inverted', '../build_db/completions_collect_word_level.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thụ\n",
      "['tại', 'tạo', 'tạp', 'tạng', 'tại chỗ', 'tại gia', 'tại sao', 'tạm thời', 'tạo hình']\n",
      "Time suggest: 0.0005178451538085938\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(search.run('thụ tinh nhân tạ'))\n",
    "print(f'Time suggest: {time.time()-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa48754237f30b58a86f79675ed681e030f5974d05e87d06b90daef74cf576c8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
